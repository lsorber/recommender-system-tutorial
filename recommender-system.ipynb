{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the MovieLens 1M data set\n",
    "\n",
    "The MovieLens 1M data set [1] dates from 2003 and contains about 1M movie ratings given by about 6k users to 4k movies. Smaller, larger, and more recent data sets are also available, but we'll go with the 1M data set in this tutorial because it's large enough that it represents a challenge and at the same time not too large to comfortably handle on a laptop.\n",
    "\n",
    "[1] http://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the `MovieLens 1M` data set with 1M movie ratings to the current directory.\n",
    "# Alternatively, try the `ml-latest-small.zip` for a smaller data set of 100k ratings.\n",
    "from urllib.request import urlretrieve\n",
    "url = 'http://files.grouplens.org/datasets/movielens/'\n",
    "filename = 'ml-1m.zip'\n",
    "urlretrieve(url + filename, filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the 100k and 1M data sets are zip files containing csv-like tables. Unfortunately, the 1M data set is provided in a less standard format, and requires a bit of parsing before we can hand it off to `pandas` for reading.\n",
    "\n",
    "The MovieLens data sets contain movie ratings, but also information about users such as their occupation and age group, and information about movies such as their genre. Although this is interesting information to improve our recommender system with, we will stick to the movie ratings for now.\n",
    "\n",
    "The movie ratings are given in long form, meaning that every observation or row represents one rating given by a particular user to a particular movie. We're also given the timestamp the rating was made, which may also help improve our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the movie ratings from the zip file.\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from io import StringIO\n",
    "filename = 'ml-1m.zip'\n",
    "with ZipFile(filename, 'r') as ml:\n",
    "    if 'small' in filename:\n",
    "        csv = filename.replace('.zip', '') + '/ratings.csv'\n",
    "        df = pd.read_csv(ml.open(csv))\n",
    "    elif '1m' in filename:\n",
    "        csv = filename.replace('.zip', '') + '/ratings.dat'\n",
    "        with ml.open(csv) as csv:\n",
    "            data = ''.join(map(lambda line: line.decode('utf-8'), csv.readlines()))\n",
    "            df = pd.read_csv(StringIO(data), sep='::', engine='python',\n",
    "                             header=None, names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data set\n",
    "\n",
    "Each row specifies a `userId` and a `movieId`, which are unique identifiers for users and movies, respectively. However, these ids do not necessarily start at zero or end at the number of users or movies. As a preprocessing step, we'll translate the user and movie ids to zero-based consecutive user and movie indices. To do this, we simply use `pandas` to convert these columns to a categorical data type, and then use the category indices as user and movie indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the `userId` and `movieId` columns to categorical.\n",
    "df.userId = df.userId.astype('category')\n",
    "df.movieId = df.movieId.astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The `userId` and `movieId` columns may contain non-consecutive numbers.\n",
    "# Here, we add the category codes to the DataFrame as a zero-based consecutive version of these ids.\n",
    "df['userIndex'] = df.userId.cat.codes\n",
    "df['movieIndex'] = df.movieId.cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data set into train, validation and test\n",
    "\n",
    "Now that we're happy with our data set, we should split it into:\n",
    "\n",
    "- a training set for optimizing our model's parameters,\n",
    "- a validation set for optimizing our model's hyperparameters (such as the number of iterations and amount of regularization), and\n",
    "- a test set for estimating the generalization performance of the resulting model.\n",
    "\n",
    "We use `sklearn`'s `train_test_split` twice to split the data set into 80%-10%-10%. With 1M ratings, a validation and test sample of 10%, or 100k ratings, should be large enough to estimate the performance. Using more than 100k ratings will not substantially reduce the variance of our performance estimate, and allocating as much as we can to the training set will help us find a better solution.\n",
    "\n",
    "Each data set consists of a feature matrix (prefixed by an uppercase `X`) and a vector of labels (prefixed by a lowercase `y`). The feature matrices only contain two features: the user index and the movie index. The labels contain the corresponding movie ratings. The indices in the feature matrices are not really features in the traditional sense of word, as their values are not directly related to the labels, but rather point to entities with a state that does influence the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split  # sklearn 0.18+\n",
    "except:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "\n",
    "n_users, n_movies = df.userIndex.max() + 1, df.movieIndex.max() + 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['userIndex', 'movieIndex']].values,\n",
    "    df['rating'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=0)\n",
    "\n",
    "print('There are {n_users} users and {n_movies} movies in the data set.'.format(n_users=n_users, n_movies=n_movies))\n",
    "print('The training, validation, and testing indices are of size {train_shape}, {validation_shape} and {test_shape}, respectively.'.format(\n",
    "    train_shape=X_train.shape, validation_shape=X_validation.shape, test_shape=X_test.shape))\n",
    "print('The labels (ratings) vary between {y_min} and {y_max}.'.format(y_min=y_train.min(), y_max=y_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up a low-rank approximation model\n",
    "\n",
    "### 4.1 Introduction to Collaborative Filtering\n",
    "\n",
    "Arguably the single best performing model in the Netflix Prize [1] is a class of collaborative filtering (CF) models called low-rank approximation (LRA), sometimes also called matrix factorization (MF). CF models such as LRA exploit the collection of user preferences (collaboration) to make item recommendations to the users (filtering). Not all recommender systems are based on CF, and a CF model does not need to be based on LRA or MF. For instance, another type of recommender system may exploit similarities between users or items to make recommendations.\n",
    "\n",
    "LRA is not just one model, but a class of models centered around a core idea. The most basic form of LRA can be improved upon substantially by incorporating time, user features, item features, and adjusting for user and item biases, among others.\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Netflix_Prize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The LRA model\n",
    "\n",
    "A basic LRA model predicts the rating $r_{u,i} \\in [0,\\, 5]$ a user $u \\in [1,\\, N]$ would give to an item $i \\in [1,\\, M]$ as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat{r}_{u,i} = \\sum_{k=1}^K a_{u,k} \\cdot b_{i,k} = \\mathbf{a}_u \\cdot \\mathbf{b}_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{a}_u$ and $\\mathbf{b}_i$ are two feature vectors of length $K$ describing the user $u$ and item $i$, respectively. As an example, let's say $K = 2$, then $r_{u,i} = a_{u,1} \\cdot b_{i,1} + a_{u,2} \\cdot b_{i,2}$. One way to interpret this model is to think of $b_{i,1}$ and $b_{i,2}$ as two numbers that describe the content of item $i$, such as the level of comedy or the movie's budget. Similarly, a user could be described by two numbers $a_{u,1}$ and $a_{u,2}$ that express that user's preference for comedic and high-budget movies. The rating user $u$ is predicted to give to item $i$ is then simply comedy content times comedy preference plus budget times budget preference. In practice, a user may take multiple such factors into consideration to arrive at a movie rating, and so it is probably reasonable to assume that $K$ should be larger than 5, but likely less than 1000.\n",
    "\n",
    "If we organize all the user feature vectors $\\mathbf{a}_u$ as rows into a matrix $A$, and all the item feature vectors $\\mathbf{b}_i$ as rows into a matrix $B$, we can predict ratings for all pairs of users $u$ and items $i$, organized in a matrix $\\hat{R}$ as:\n",
    "\n",
    "$$\n",
    "    \\hat{R} = A \\cdot B^{\\mathrm{T}}\n",
    "$$\n",
    "\n",
    "where $\\hat{R}$ is an $N$ by $M$ matrix where every row corresponds to a user and every column to an item. This compact formula also shows where the names LRA and MF stem from: the predicted rating matrix $\\hat{R}$ is a matrix factorization of low-rank, the rank being the number $K$.\n",
    "\n",
    "The matrices $A$ and $B$ are called factors of the matrix factorization $\\hat{R}$, and are the parameters of the LRA model. Once we have learned the features for all users and movies, we can predict all entries of $\\hat{R}$ with the formula above. One problem with this is that there is nothing that guarantees that our predicted ratings will be between 0 and 5. To fix this shortcoming, we will apply a transformation to each individual prediction in $\\hat{R}$ to restrict the output to that range, whatever the input:\n",
    "\n",
    "$$\n",
    "    \\hat{R}' = 5\\cdot \\mathrm{sigmoid}(\\hat{R}) = \\frac{5}{1 + \\exp\\left(-\\hat{R}\\right)}\n",
    "$$\n",
    "\n",
    "As $\\hat{R}$ goes to positive infinity, the exponential tends to zero and $\\hat{R}'$ will go to 5. Conversely, if $\\hat{R}$ goes to negative infinity, the exponential tends to infinity and $\\hat{R}'$ will go to 0.\n",
    "\n",
    "Now that we have predictions $\\hat{R}'$, we need to be able to compare them to the measured ratings. First, let's also organize all the measured ratings in a matrix $R$ of the same size as $\\hat{R}'$, namely $N$ by $M$. Although we know 1M entries of the matrix $R$, there are many more that we don't know (there are about 6k x 4k = 24M entries total). In the movie recommendation setting, a common way to compare a set of predicted ratings with true ratings is called the root-mean-square error (RMSE):\n",
    "\n",
    "$$\n",
    "    \\mathrm{RMSE}(\\hat{R}', R) = \\sqrt{\\frac{1}{T} \\sum_{u,i} \\left(\\hat{r}'_{u,i} - r_{u,i}\\right)^2 }\n",
    "$$\n",
    "\n",
    "where the summation is taken over the known ratings of the matrix $R$ and $T$ is the total number of such ratings. The RMSE has the tendency to penalize false positives (\"trust busters\") and false negatives (\"missed opportunities\") more strongly due to the square, and can be thought of as way to measure the average number of incorrect stars between the predictions and true ratings.\n",
    "\n",
    "Finally, our objective is not only to fit the training data by minimizing the RMSE, but also to prevent the parameters from overfitting by adding, for instance, a regularization term of the form\n",
    "\n",
    "$$\n",
    "    \\mathrm{L2}(A, B) = \\sum_{u,k} a_{u,k}^2 + \\sum_{i,k} b_{i,k}^2\n",
    "$$\n",
    "\n",
    "so that our optimization problem becomes\n",
    "\n",
    "$$\n",
    "    \\mathrm{minimize}_{A,B}\\quad \\left[\\mathrm{loss}(A, B) = \\mathrm{RMSE}(\\hat{R}', R) + \\lambda \\cdot \\mathrm{L2}(A, B)\\right]\n",
    "$$\n",
    "for a given $R$ and some choice of the hyperparameters $K$ and $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model implementation\n",
    "\n",
    "To implement the model, all we need to do is implement its components:\n",
    "\n",
    "- the RMSE function,\n",
    "- the L2 function,\n",
    "- the sigmoid function,\n",
    "- the prediction function $\\hat{R}'$, and\n",
    "- the loss function.\n",
    "\n",
    "The cells below provide you with a skeleton of each of these functions. It will be up to you to implement them using nothing but `numpy`. Each function has a docstring that explains what the expected inputs and outputs are. You'll know if your implementation is correct if the assert statements following each function don't produce any exceptions. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll be using a thin wrapper around numpy called autograd.\n",
    "# Later on, autograd will provide us with a gradient of the loss function automatically.\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmse(predicted_ratings, true_ratings):\n",
    "    \"\"\"Root-mean-square error.\n",
    "    \n",
    "    Args:\n",
    "        predicted_ratings (np.array): A numpy array containing the predicted ratings.\n",
    "        true_ratings (np.array): A numpy array of the same length as `predicted_ratings` containing the true ratings.\n",
    "    \n",
    "    Returns:\n",
    "        np.float64: The RMSE between the two input vectors of length N, defined as:\n",
    "        \n",
    "            \\sqrt{1/N \\sum_i (predicted_rating[i] - true_rating[i])^2}.\n",
    "    \"\"\"\n",
    "    # TODO: rmse = \n",
    "    return rmse\n",
    "\n",
    "# Test if our implementation works.\n",
    "assert rmse(np.array([1, 5]), np.array([1, 5])) == 0.  # Perfect predictions.\n",
    "assert rmse(np.array([2, 5]), np.array([4, 3])) == 2.  # Two stars incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def L2(userfeatures, moviefeatures):\n",
    "    \"\"\"L2 regularization.\n",
    "    \n",
    "    Args:\n",
    "        userfeatures (np.ndarray): An n_users x k array, where k is the number of features per user.\n",
    "        moviefeatures (np.ndarray): An n_movies x k array, where k is the number of features per movie.\n",
    "    \n",
    "    Returns:\n",
    "        np.float64: The sum of the squares of the entries of both arguments:\n",
    "        \n",
    "            \\sum_{u,k} userfeatures[u, k] ** 2 + \\sum_{i,k} moviefeatures[i, k] ** 2\n",
    "    \"\"\"\n",
    "    # TODO: L2 = \n",
    "    return L2\n",
    "\n",
    "# Test if our implementation works.\n",
    "userfeatures = np.array([[1.0, 0.5], [0.0, -2.0]])\n",
    "moviefeatures = np.array([[1.0, 2.0], [0.5, 1.0]])\n",
    "assert L2(userfeatures, moviefeatures) == 11.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"A logistic sigmoid transformation.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarrray): A numpy array.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: An array of the same size as x, transformed to the range (0, 1) as:\n",
    "        \n",
    "            1 / (1 + exp(-x))\n",
    "    \"\"\"\n",
    "    #TODO: sigmoid = \n",
    "    return sigmoid\n",
    "\n",
    "x = np.linspace(-10., 10., 100)\n",
    "y = 5. * sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x'); plt.ylabel('5 * sigmoid(x)')\n",
    "plt.ylim(-1, 6); plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_ratings(userfeatures, moviefeatures, userindices, movieindices):\n",
    "    \"\"\"Make predictions with a low-rank approximation model.\n",
    "    \n",
    "    Args:\n",
    "        userfeatures (np.ndarray): An n_users x k array, where k is the number of features per user.\n",
    "        moviefeatures (np.ndarray): An n_movies x k array, where k is the number of features per movie.\n",
    "        userindices (np.array): An array of user indices to predict ratings for.\n",
    "        movieindices (np.array): An array of movie indices to predict ratings for.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: For every pair of userindex and movieindex in `userindices` and `movieindes`,\n",
    "            predicts the rating the corresponding user would give to that movie as the dot product\n",
    "            between the user features and the movie features:\n",
    "            \n",
    "                5 * sigmoid(\\sum_i userfeatures[userindex, i] * moviefeatures[movieindex, i])\n",
    "    \"\"\"\n",
    "    # TODO: predicted_ratings = \n",
    "    return predicted_ratings\n",
    "    \n",
    "# Test if our implementation works.\n",
    "userfeatures = np.array([[1.0, 0.5], [0.0, -2.0]])\n",
    "moviefeatures = np.array([[1.0, 2.0], [0.5, 1.0]])\n",
    "userindices = np.array([0, 0, 1, 1])\n",
    "movieindices = np.array([0, 0, 1, 1])\n",
    "assert np.all(predict_ratings(userfeatures, moviefeatures, userindices, movieindices) >= 0.)\n",
    "assert np.all(predict_ratings(userfeatures, moviefeatures, userindices, movieindices) <= 5.)\n",
    "assert np.all(np.isclose(predict_ratings(userfeatures, moviefeatures, userindices, movieindices), np.array([4.404, 4.404, 0.596, 0.596]), rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss(weights, userindices=None, movieindices=None, true_ratings=None, regL2=0.):\n",
    "    \"\"\"Given the user and movie features, predict the ratings and compare with the true ratings.\n",
    "    \n",
    "    Args:\n",
    "        weights (tuple): The user features and movie features as a tuple of the form (np.ndarray, np.ndarray).\n",
    "        userindices (np.array): An array of user indices to predict ratings for.\n",
    "        movieindices (np.array): An array of movie indices to predict ratings for.\n",
    "        true_ratings (np.array): A numpy array containing the true ratings.\n",
    "        regL2 (float): The coefficient for the L2 regularization term of the loss function.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: The RMSE between the predicted ratings generated with `predict_ratings`,\n",
    "            and the given `true_ratings`, summed with regL2 times the L2 norm of the weights:\n",
    "            \n",
    "                rmse(predicted_ratings, true_ratings) + regL2 * L2(userfeatures, moviefeatures)\n",
    "    \"\"\"\n",
    "    # Unpack the weights tuple into the user and movie features to pass to `predict_ratings`.\n",
    "    userfeatures, moviefeatures = weights\n",
    "    # Predict the ratings.\n",
    "    # TODO: predicted_ratings = \n",
    "    # Compute the loss as the RMSE between the predicted and the true ratings,\n",
    "    # summed with regL2 times the L2 norm of the user- and moviefeatures.\n",
    "    # TODO: loss = \n",
    "    return loss\n",
    "\n",
    "# Test if our implementation works.\n",
    "userfeatures = np.array([[1.0, 0.5], [0.0, -2.0]])\n",
    "moviefeatures = np.array([[1.0, 2.0], [0.5, 1.0]])\n",
    "userindices = np.array([0, 0, 1, 1])\n",
    "movieindices = np.array([0, 0, 1, 1])\n",
    "true_ratings = np.array([2., 2., -2., 0.])\n",
    "assert np.isclose(loss((userfeatures, moviefeatures), userindices, movieindices, true_ratings), 2.159, rtol=1e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement a training algorithm\n",
    "\n",
    "If you made it to here and see no exceptions, good job! In the next cell, we've implemented a variant of a stochastic gradient descent (SGD) algorithm called ADAM that will find the optimal `userfeatures` and `moviefeatures` for us by minimizing the `loss` function.\n",
    "\n",
    "Every iteration, a slice of a few hundred samples called a mini-batch is taken from `X_train` and `y_train`, generated by `minibatch_indices`. The `minibatch_loss` function passes those on to `loss`, which computes the loss on that mini-batch. The SGD algorithm doesn't actually need to call `minibatch_loss` itself every iteration. Rather, it calls the gradient of `minibatch_loss`, which is computed for us automatically by the autograd package. At every iteration, the (negative of the) gradient points to the direction in which the loss function decreases. Gradient descent algorithms update the solution by taking a small step in that direction every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def minibatch_indices(it, minibatch_size):\n",
    "    \"\"\"Returns a slice of indices given the iteration number.\"\"\"\n",
    "    num_batches = int(np.ceil(X_train.shape[0] / minibatch_size))\n",
    "    it = it % num_batches\n",
    "    return slice(it * minibatch_size, (it + 1) * minibatch_size)\n",
    "\n",
    "def minibatch_loss(weights, it, regL2=0., minibatch_size=512):\n",
    "    \"\"\"Computes the loss on a slice of training samples generated by `minibatch_indices`.\"\"\"\n",
    "    # Get the indices of the samples we want to optimize in this iteration.\n",
    "    indices = minibatch_indices(it, minibatch_size)\n",
    "    userindices, movieindices, true_ratings = X_train[indices, 0], X_train[indices, 1], y_train[indices]\n",
    "    return loss(weights, userindices, movieindices, true_ratings, regL2)\n",
    "\n",
    "# Define some functions that we can call with our weights\n",
    "# to evaluate the training, validation and test performance.\n",
    "from functools import partial\n",
    "subset = np.random.choice(len(y_train), len(y_validation), replace=False)\n",
    "full_training_rmse = partial(loss, userindices=X_train[subset, 0], movieindices=X_train[subset, 1], true_ratings=y_train[subset])\n",
    "full_validation_rmse = partial(loss, userindices=X_validation[:, 0], movieindices=X_validation[:, 1], true_ratings=y_validation)\n",
    "full_test_rmse = partial(loss, userindices=X_test[:, 0], movieindices=X_test[:, 1], true_ratings=y_test)\n",
    "\n",
    "def plot_convergence(epochs, training_rmse_log, validation_rmse_log):\n",
    "    \"\"\"Plots the convergence of the training and validation RMSE.\"\"\"\n",
    "    best = np.argmin(validation_rmse_log)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, training_rmse_log, label='Training RMSE')\n",
    "    plt.plot(epochs, validation_rmse_log, label='Validation RMSE')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    btm = 0.9 * min(training_rmse_log)\n",
    "    top = 1.1 * max(training_rmse_log)\n",
    "    plt.xlim(epochs.min(), epochs.max()); plt.ylim(btm, top)\n",
    "    plt.plot([epochs[best], epochs[best]], [btm, top])\n",
    "    plt.xlabel('epoch'); plt.ylabel('RMSE'); plt.grid()\n",
    "    plt.title('Best validation RMSE is {rmse:.3f} at epoch {epoch:.2f}'.format(\n",
    "        rmse=validation_rmse_log[best], epoch=epochs[best]))\n",
    "\n",
    "# The ADAM algorithm adapted from [1] for this tutorial.\n",
    "# [1] https://github.com/HIPS/autograd/blob/master/autograd/optimizers.py\n",
    "from autograd.util import flatten_func\n",
    "from tqdm import trange\n",
    "def adam(grad, init_params, n_epochs=2., step_size=1e-3,\n",
    "         b1=0.9, b2=0.999, eps=1e-8, log_steps=100, minibatch_size=512):\n",
    "    \"\"\"Adam as described in http://arxiv.org/pdf/1412.6980.pdf.\"\"\"\n",
    "    # Run ADAM for num_iters epochs.\n",
    "    flattened_grad, unflatten, x = flatten_func(grad, init_params)\n",
    "    m, v = np.zeros(len(x)), np.zeros(len(x))\n",
    "    training_rmse_log, validation_rmse_log = [], []\n",
    "    num_iters = int(np.round(n_epochs * len(y_train) / minibatch_size))\n",
    "    log_steps = np.round(np.linspace(0, num_iters - 1, min(log_steps, num_iters)))\n",
    "    best_loss, best_x = np.inf, None\n",
    "    for i in trange(num_iters, unit='minibatch'):\n",
    "        g = flattened_grad(x, i)\n",
    "        m = (1 - b1) * g      + b1 * m  # First  moment estimate.\n",
    "        v = (1 - b2) * (g**2) + b2 * v  # Second moment estimate.\n",
    "        mhat = m / (1 - b1**(i + 1))    # Bias correction.\n",
    "        vhat = v / (1 - b2**(i + 1))\n",
    "        x = x - step_size*mhat/(np.sqrt(vhat) + eps)\n",
    "        if i in log_steps:\n",
    "            training_rmse_log.append(full_training_rmse(unflatten(x)))\n",
    "            validation_rmse_log.append(full_validation_rmse(unflatten(x)))\n",
    "            if (len(validation_rmse_log) > 1) and (validation_rmse_log[-1] < best_loss):\n",
    "                best_loss, best_x = validation_rmse_log[-1], x\n",
    "    # Plot the results on training and validation set.\n",
    "    epochs = log_steps * minibatch_size / len(y_train)\n",
    "    plot_convergence(epochs, training_rmse_log, validation_rmse_log)\n",
    "    return unflatten(best_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(config, initial_weights=None):\n",
    "    \"\"\"Train the LRA model.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): A dictionary of configuration parameters for the model and algorithm.\n",
    "        initial_weights (tuple): A tuple of the form (np.ndarray, np.ndarray), containing\n",
    "            the initial userfeatures and moviefeatures to start with, respectively. If None,\n",
    "            they are initialized with `np.random.randn`.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple of (userfeatures, moviefeatures) that performed best on the\n",
    "            validation set during training.\n",
    "    \"\"\"\n",
    "    # Initialize the user features and movie features.\n",
    "    if initial_weights is None:\n",
    "        np.random.seed(42)\n",
    "        initial_weights = (0.1 * np.random.randn(n_users, config['k']),\n",
    "                           0.1 * np.random.randn(n_movies, config['k']))\n",
    "    # Configure the mini-batch loss.\n",
    "    configured_minibatch_loss = partial(\n",
    "        minibatch_loss,\n",
    "        regL2=config['regL2'],\n",
    "        minibatch_size=config['minibatch_size'])\n",
    "    # Compute the gradient of the mini-batch loss.\n",
    "    minibatch_loss_gradient = grad(configured_minibatch_loss)\n",
    "    # Iteratively improve the solution by using the gradient to take a step that improves the loss.\n",
    "    weights = adam(\n",
    "        minibatch_loss_gradient,\n",
    "        initial_weights,\n",
    "        n_epochs=config['n_epochs'],\n",
    "        step_size=config['step_size'],\n",
    "        log_steps=config['log_steps'],\n",
    "        minibatch_size=config['minibatch_size'])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and evaluate the model\n",
    "\n",
    "The `train` function accepts a `config` dictionary that specifies all of the different parameters of our model and algorithm:\n",
    "\n",
    "- `k`: the number of features each user and movie are represented by,\n",
    "- `regL2`: the amount of L2 regularization in the loss function,\n",
    "- `minibatch_size`: the number of samples taken from the training set to compute the gradient with in every iteration,\n",
    "- `step_size`: the size of the update added to the solution every iteration,\n",
    "- `n_epochs`: one iteration updates the solution with a single mini-batch, while the number of epochs represents the number of times the algorithm has gone through the whole training data set to update the solution, and\n",
    "- `log_steps`: the number of times the validation performance is evaluated during training.\n",
    "\n",
    "There is also an optional `initial_weights` argument if you want to supply your own initial solution. If it is `None`, the solution is initialized as a tuple `(userfeatures, moviefeatures)` with `np.random.randn`, cf. `train` for details.\n",
    "\n",
    "The output of `train` is the solution that had the best performance on the validation set during training.\n",
    "\n",
    "### 6.1 Generating a decent initial solution\n",
    "\n",
    "We'll first run a few iterations of the algorithm on a randomly initialized solution to obtain a higher quality solution that we can use to jump start our subsequent training steps.\n",
    "\n",
    "We'll keep iterating through mini-batches of 512 samples until the algorithm has seen half of the training data, which we specify with `n_epochs: 0.5`. This keeps the training time short, and at the same time allows us to set `regL2` to zero, since there is little risk of overfitting the training data if we train for such a short amount of epochs.\n",
    "\n",
    "Once training the initial solution has completed, answer the following questions:\n",
    "\n",
    "- Is there a significant difference between training RMSE and validation RMSE?\n",
    "- What does this tell you about the amount of overfitting of the obtained solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'k': 8,\n",
    "    'regL2': 0.,\n",
    "    'minibatch_size': 512,\n",
    "    'step_size': 5e-3,\n",
    "    'n_epochs': 0.5,\n",
    "    'log_steps': 100\n",
    "}\n",
    "initial_weights = train(config, initial_weights=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 In search of the best solution\n",
    "\n",
    "Now we can use the previously obtained `initial_solution` to try and find a better one. Since it was going well, let's first simply increase the number of epochs to 10, so that the training algorithm will have seem the full training set 10 times over.\n",
    "\n",
    "Once training the initial solution has completed, answer the following questions:\n",
    "\n",
    "- At what epoch do the training and validation RMSEs achieve their minima?\n",
    "- What other indicator of overfitting do you observe?\n",
    "- Try increasing `regL2` to `1e-5` and confirm that this improves both of the above effects. Why does this help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'k': 8,\n",
    "    'regL2': 0.,\n",
    "    'minibatch_size': 512,\n",
    "    'step_size': 5e-3,\n",
    "    'n_epochs': 10.,\n",
    "    'log_steps': 100\n",
    "}\n",
    "weights = train(config, initial_weights=initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'k': 8,\n",
    "    'regL2': 1e-5,\n",
    "    'minibatch_size': 512,\n",
    "    'step_size': 5e-3,\n",
    "    'n_epochs': 10.,\n",
    "    'log_steps': 100\n",
    "}\n",
    "weights = train(config, initial_weights=initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_test_rmse(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Where to go from here\n",
    "\n",
    "The LRA model gets us some pretty nice results, but there are still many opportunities to improve them. Here are some ideas you can try:\n",
    "\n",
    "- What is the RMSE performance of just using the mean rating per movie as a predictor?\n",
    "- What is the RMSE performance of just using the mean rating per user as a predictor?\n",
    "- Some movies get rated consistently lower or higher than others. Similarly, some users consistently rate movies lower or higher than other users. Taking this into account, we could update our model to include these biases by writing: $\\hat{r}_{u,i} = p_u + q_i + \\sum_{k=1}^K a_{u,k} \\cdot b_{i,k}$, where $p_u$ is the user $u$'s bias, and $q_i$ is the movie $i$'s bias. Both the user and movie bias can be initialized neatly using the answers to the previous two questions. How much better does the biased LRA model perform?\n",
    "- MovieLens also gives us access to each rating's timestamp. We could take time's effect into account in our model in two ways: with a simple time bias, and by adding the effect of time to each of the user and movie features. Combining both effects, our model would be: $\\hat{r}_{u,i,t} = p_u + q_i + v_t + \\sum_{k=1}^K a_{u,k} \\cdot b_{i,k} \\cdot c_{t,k}$, where $v_t$ is the bias due to time, and $c_{t,k}$ is the effect of time on the features. Notice that our model $\\hat{r}_{u,i,t}$ now allows us to predict ratings for users given to items _at a specific timestamp_! In fact, because of the extra time dimension, we are now looking at a tensor factorization (TF) model. How much better does the biased temporal LRA model perform?\n",
    "- A known weakness of the LRA model is that it does not perform well on new users and movies, since they have no or few ratings to base the predictions on. A good way to deal with this cold-start problem is to exploit additional information we have available on the users and movies, such as age group, occupancy, genre, director, year, and so on. Incorporating this information in our model can be done elegantly with so-called coupled matrix and tensor factorization, also known as multi-relational learning, and data fusion. A good starting point is Rendle's Factorization Machines paper [1].\n",
    "\n",
    "[1] http://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:recsys-env]",
   "language": "python",
   "name": "conda-env-recsys-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
